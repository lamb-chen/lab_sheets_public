





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from skimage import io
from sklearn.datasets import fetch_california_housing
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error





# write your code here

A = np.array([[2, 3], [4, -1], [5, 6]])
B = np.array([[5, 2], [8, 9], [2, 1]])

C = 3*A
print("C:", C)

C = A + B
print("C:", C)


C = np.dot(A, B.T)
print("C:", C)

# Hadamard product or elementwise product
C = A * B # or C = np.multiply(A, B)
print("C:", C)





# write your code here
mean = np.mean(A)
sum = np.sum(A)
var = np.var(A)

print("Mean:", mean)
print("Sum:", sum)
print("Var:", var)

# Asum_row = A.sum(axis=1)
# print('A sum (row):', Asum_row)

# Asum_col = A.sum(axis=0)
# print('A sum (column):', Asum_col)
      





# write your code here
def sigmoid(x):
    sig = 1/(1+ np.exp(-x))
    return sig






# write your code here
A = np.array([-5, 0, 5])
print(sigmoid(A))





# write your code here
def standardiseCols(x):
    # Calculate the mean of each column
    means = np.mean(x, axis=0)
    
    # Calculate the standard deviation of each column
    stds = np.std(x, axis=0)
    
    # Subtract the mean and divide by the standard deviation
    standardized_x = (x - means) / stds
    
    return standardized_x







# write your code here
x = np.array([
    [0, 3, 5],
    [1, 6, 4],
    [3, -2, 8],
    [-1, 1, 10]
])
y = standardiseCols(x)
print(np.mean(y))
print(np.std(y))





image = io.imread('flower.png')
io.imshow(image)
image.shape





# write your code here
print(image.reshape(-1, 1))





a = np.arange(5)
print(a)
print(a.shape)
print(a.T)
print(a.T.shape)





a = a.reshape(1,-1)
print(a)
a.shape





a = a.reshape(-1,1)
print(a)
a.shape





assert(a.shape == (5,1))








# write your code here
housing = fetch_california_housing()
print(housing.data.shape)
print(housing.feature_names)
housingDf = pd.DataFrame(housing.data, columns=housing.feature_names)
sns.pairplot(housingDf, height=2.5)
plt.show()








# write your code here
scaler = StandardScaler(with_mean=True, with_std=True)
scaler.fit(housing.data)
x = scaler.transform(housing.data)
print(np.mean(x))
print("Mean of scaled data:", np.mean(x, axis=0)) 
print("Standard deviation of scaled data:", np.std(x, axis=0))





# write your code here
housing = fetch_california_housing()
X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.3)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)





# write your code here
reg = LinearRegression().fit(X_train, y_train)
reg.coef_





# write your code here
from sklearn.metrics import root_mean_squared_error
pred = reg.predict(X_test)
root_mean_squared_error(pred, y_test)
plt.scatter(pred, y_test)






np.random.seed(0)
N = 30
sigma = 5
x = np.sort(np.random.sample((N,1)))*10
y = (x-1)*(x-5) + np.random.normal(0,sigma,N).reshape(-1, 1)

fig, ax = plt.subplots(figsize=(6,4))
ax.scatter(x, y)
ax.set_xlabel('x')
ax.set_ylabel('y')





# write your code here
X_bias = 






# write your code here






# write your code here










